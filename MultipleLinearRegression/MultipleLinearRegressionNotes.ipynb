{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "We have a dataset to analyze success of start up based on various parameters...\n",
    "\n",
    "- Dummy variable for categorical variables\n",
    "for ex: State column values are NY and CA, we have to transpose and covert these values in to columns. Actually we don't need to consider both of these columns in your Regression model because NY column itself capturing all the variation\n",
    "\n",
    "your columns\n",
    "Dependent   Independent variables\n",
    "Profit      R&D, Admin, Marketing, State\n",
    "\n",
    "Formulat\n",
    "\n",
    "y = b0 + b1*x1 + b2*x2 + b3*x3    + b4*X4[this is for categorical column]\n",
    "\n",
    "It is easy if we have single independent variable then it is easy to decide and build regression model\n",
    "\n",
    "but with lot of variables we need to decide which ones to keep which ones to eliminate\n",
    "\n",
    "why\n",
    "\n",
    "1) Garbage in - Garbage out\n",
    "\n",
    "2) Explainability\n",
    "\n",
    "#### 5 Methods of building models\n",
    "\n",
    "1. All-in\n",
    "2. Backward Elimination\n",
    "3. Forward selection\n",
    "4. Bidirectional elimination\n",
    "5. score comparison\n",
    "\n",
    "2,3,4 are stepwise regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.All-in\n",
    "\n",
    "-   Throw in all variables. This can be decided using prior knowledge or built a model already\n",
    "-   You have to use all variables\n",
    "-   Preparing for Backword Elimination\n",
    "\n",
    "### 2. Backward Elimination\n",
    "\n",
    "- Select significance level to stay in the model(SL = 0.05)\n",
    "- Fit full model with all possible predictors\n",
    "- Consider the predictor[Independent variable] with highest P-value. If P > SL, go to step 4 otherwise done.[Simple english review all the independent variable and thier P-value and check whether they impact the dependent variable or not. if P-value > SL then they won't]\n",
    "- Remove the predictor\n",
    "- Fit model without this variable [repeat from Step 3]\n",
    "\n",
    "\n",
    "For example: Number of windows of a house won't impact the price of the house this can be understood by P-value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Removed: size, P-value: 0.5682448463623814\n",
      "❌ Removed: windows, P-value: 0.2221852348118141\n",
      "\n",
      "Final Selected Features: ['location']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "size = np.random.rand(20) * 2000  # House size in sq ft\n",
    "location = np.random.randint(1, 10, 20)  # Location rating (1-10)\n",
    "windows = np.random.randint(1, 20, 20)  # Number of windows\n",
    "price = 5000 + 3 * size + 10000 * location + 50 * windows + np.random.normal(0, 10000, 20)  # House price\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'size': size, 'location': location, 'windows': windows, 'price': price})\n",
    "X = df[['size', 'location', 'windows']]\n",
    "y = df['price']\n",
    "\n",
    "# Backward Elimination Function\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    selected_features = list(X.columns)\n",
    "\n",
    "    while len(selected_features) > 0:\n",
    "        model = LinearRegression().fit(X[selected_features], y)\n",
    "        _, p_values = f_regression(X[selected_features], y)\n",
    "        worst_p_value = max(p_values)  # Find highest P-value\n",
    "        \n",
    "        if worst_p_value > significance_level:\n",
    "            worst_feature = selected_features[p_values.argmax()]\n",
    "            selected_features.remove(worst_feature)\n",
    "            print(f\"❌ Removed: {worst_feature}, P-value: {worst_p_value}\")\n",
    "        else:\n",
    "            break  # Stop when all features are significant\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Run Backward Elimination\n",
    "selected_features = backward_elimination(X, y)\n",
    "print(\"\\nFinal Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Forward selection\n",
    "\n",
    "1. Select the significance level to enter the model(for ex: SL=0.05)\n",
    "2. Fit all simple regression models y ~ Xn select the one with lowest P-value\n",
    "3. Keep this variable and fit all possible models with one extra predictor added to the one's you have already selected\n",
    "4. Consider the predictor with lowest P-value. If P < SL then go to step 3, otherwise go to Final..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: size, P-value: 0.5682448463623814\n",
      "Feature: location, P-value: 1.928929878013406e-09\n",
      "Feature: windows, P-value: 0.2221852348118144\n",
      "Added: location, P-value: 1.928929878013406e-09\n",
      "Feature: size, P-value: 0.5682448463623814\n",
      "Feature: windows, P-value: 0.2221852348118141\n",
      "\n",
      "Final Selected Features: ['location']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "size = np.random.rand(20) * 2000  # House size in sq ft\n",
    "location = np.random.randint(1, 10, 20)  # Location rating (1-10)\n",
    "windows = np.random.randint(1, 20, 20)  # Number of windows\n",
    "price = 5000 + 3 * size + 10000 * location + 50 * windows + np.random.normal(0, 10000, 20)  # House price\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'size': size, 'location': location, 'windows': windows, 'price': price})\n",
    "X = df[['size', 'location', 'windows']]\n",
    "y = df['price']\n",
    "\n",
    "# Forward Selection Function\n",
    "def forward_selection(X, y):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    while remaining_features:\n",
    "        best_p_value = 1\n",
    "        best_feature = None\n",
    "        for feature in remaining_features:\n",
    "            model = LinearRegression().fit(X[selected_features + [feature]], y)\n",
    "            _, p_values = f_regression(X[selected_features + [feature]], y)\n",
    "            p_value = p_values[-1]  # P-value of the newly added feature\n",
    "            print(f\"Feature: {feature}, P-value: {p_values[-1]}\")  # Debugging line\n",
    "            if p_value < 0.05 and p_value < best_p_value:\n",
    "                best_p_value = p_value\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_feature is None:\n",
    "            break  # Stop when no feature meets the threshold\n",
    "        \n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "        print(f\"Added: {best_feature}, P-value: {best_p_value}\")\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Run Forward Selection\n",
    "selected_features = forward_selection(X, y)\n",
    "print(\"\\nFinal Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Bidrectional Elimination\n",
    "\n",
    "1. Select a significance level to enter and stay in the model. For SLENTER = 0.05 and SLSTAY=0.05\n",
    "2. Perform the next step of the Forward selection(new variables must have P < SLENTER)\n",
    "3. Perform all steps of the Backward elimination (old variables must have P < SLSTAY)\n",
    "4. Exit if no new variables can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added: location, P-value: 1.928929878013406e-09\n",
      "\n",
      "Final Selected Features: ['location']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "size = np.random.rand(20) * 2000  # House size in sq ft\n",
    "location = np.random.randint(1, 10, 20)  # Location rating (1-10)\n",
    "windows = np.random.randint(1, 20, 20)  # Number of windows\n",
    "price = 5000 + 3 * size + 10000 * location + 50 * windows + np.random.normal(0, 10000, 20)  # House price\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'size': size, 'location': location, 'windows': windows, 'price': price})\n",
    "X = df[['size', 'location', 'windows']]\n",
    "y = df['price']\n",
    "\n",
    "# Bidirectional Elimination Function\n",
    "def bidirectional_elimination(X, y, significance_level=0.05):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "\n",
    "    while remaining_features:\n",
    "        # Forward Step: Add best feature\n",
    "        best_p_value = 1\n",
    "        best_feature = None\n",
    "        for feature in remaining_features:\n",
    "            model = LinearRegression().fit(X[selected_features + [feature]], y)\n",
    "            _, p_values = f_regression(X[selected_features + [feature]], y)\n",
    "            p_value = p_values[-1]  # P-value of the newly added feature\n",
    "            if p_value < significance_level and p_value < best_p_value:\n",
    "                best_p_value = p_value\n",
    "                best_feature = feature\n",
    "        \n",
    "        if best_feature is None:\n",
    "            break  # Stop if no significant feature is found\n",
    "        \n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "        print(f\"✅ Added: {best_feature}, P-value: {best_p_value}\")\n",
    "\n",
    "        # Backward Step: Remove least significant feature\n",
    "        while selected_features:\n",
    "            model = LinearRegression().fit(X[selected_features], y)\n",
    "            _, p_values = f_regression(X[selected_features], y)\n",
    "            worst_p_value = max(p_values)\n",
    "            if worst_p_value > significance_level:\n",
    "                worst_feature = selected_features[p_values.argmax()]\n",
    "                selected_features.remove(worst_feature)\n",
    "                remaining_features.append(worst_feature)\n",
    "                print(f\"❌ Removed: {worst_feature}, P-value: {worst_p_value}\")\n",
    "            else:\n",
    "                break  # Stop when all selected features are significant\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Run Bidirectional Elimination\n",
    "selected_features = bidirectional_elimination(X, y)\n",
    "print(\"\\nFinal Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.All possible models\n",
    "Name suggest that build models for all subsets possible and pick the best one. for ex: 10 variables dataset will have 1024 models probably. very expensive and doesn't scale.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
