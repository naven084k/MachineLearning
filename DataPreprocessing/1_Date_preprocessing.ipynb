{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Processing for a Machine Learning Model**\n",
    "\n",
    "Data processing is process of cleaning, transforming, and preparing raw data for a ML model. \n",
    "Proper data processing improves model accuracy, efficiency, and generalization. This includes various steps\n",
    "- Handling missing values\n",
    "- Remove Duplicates\n",
    "- Inconsistent formatting(Date formats or capitalization or number formatting)\n",
    "- Feature encoding(ML models only work on numerical data, we need to convert categories values into numerical values, for ex: column of female and male in to 0 and 1)\n",
    "- Feature scaling\n",
    "- Dimensionality reduction\n",
    "- Handling imbalanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a data frame. this is a in memory table\n",
    "dataset = pd.read_csv('./Data.csv')\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country      0\n",
      "Age          1\n",
      "Salary       1\n",
      "Purchased    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Handling missing values\n",
    "## Identifying how many null values are there?\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(X[:,1:3])\n",
    "X[:,1:3] = imputer.transform(X[:,1:3])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical data\n",
    "\n",
    "Machine learning model training doesn't understand string values. In above Country names is a string but we can't also convert them in 1,2,3 etc why because 3 gains more precedence and model becomes biased. That's why we use one hot encoding. This allows creating binary vector\n",
    "\n",
    "France Spain Germany\n",
    "1       0      0\n",
    "0       1      0\n",
    "0       1      1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[(\"encoder\",OneHotEncoder(),[0])],remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "## Future machine learning model training .fit function expects a numpy array. that's why we are casting\n",
    "\n",
    "print(X)\n",
    "\n",
    "## Convert dependency variable y into 1 and 0 using label encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "[0 1 0 0 1 1 0 1]\n",
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data set for training and testing..\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test) \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "#### Example: Why Feature Scaling is Needed\n",
    "#### Scenario: Predicting House Prices\n",
    "\n",
    "Suppose you have a dataset with two features:\n",
    "\n",
    "House Size (in square feet) → Range: 500 to 5000\n",
    "Number of Bedrooms → Range: 1 to 5\n",
    "If you use a machine learning model like Linear Regression or k-NN, the large numerical range of \"House Size\" (500–5000) will dominate the smaller range of \"Number of Bedrooms\" (1–5). The model will assign more importance to \"House Size,\" even if \"Number of Bedrooms\" is equally important.\n",
    "\n",
    "Effect Without Feature Scaling\n",
    "The model might assume \"House Size\" is much more important just because it has larger values, leading to biased predictions.\n",
    "\n",
    "Applying Feature Scaling\n",
    "If we apply Min-Max Scaling:\n",
    "\n",
    "House Size (500 to 5000) → Scaled to 0 to 1\n",
    "Number of Bedrooms (1 to 5) → Scaled to 0 to 1\n",
    "Now, both features have equal weight, improving the model’s learning ability and prediction accuracy.\n",
    "\n",
    "## Common techniques\n",
    "#### 1. Normalization[Min-max scaling]\n",
    "      New_x = (X - X_min)/(X_max-X_min)\n",
    "#### 2. Standardization[z-score normalization]\n",
    "      New_x = (X - avg)/standard deviation\n",
    "\n",
    "Feature scaling has to be done after splitting the data because your model is supposed to be consider standard values of the train data set but not test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n",
    "X_test[:,3:] = sc.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
